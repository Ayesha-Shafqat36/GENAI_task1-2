{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ac5f46-7dfd-4827-8b22-d6dbf0cacfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e0894a-a8e4-4eec-bfd3-9b980c9294e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Solidity  Eccentricity  EquivDiameter  Extrema  FilledArea  \\\n",
      "0           0     10.70          15.8           5.43     3.75       0.785   \n",
      "1           1      5.60          18.3           4.14     6.16       0.364   \n",
      "2           2      8.32          19.8           4.63     6.66       0.415   \n",
      "3           3     10.10          17.9           7.29    11.10       1.470   \n",
      "4           4      6.27          20.2          20.10    10.70      14.700   \n",
      "\n",
      "   Extent  Orientation  EulerNumber  BoundingBox1  ...  ConvexHull4  \\\n",
      "0    8.14         2.15         22.3          2.97  ...         2.97   \n",
      "1    3.51        18.60         22.5          5.41  ...         5.47   \n",
      "2    5.85        21.00         22.4          5.96  ...         5.96   \n",
      "3    6.30         9.94         21.9          8.81  ...         8.88   \n",
      "4    3.97         2.58         11.9         10.20  ...        10.20   \n",
      "\n",
      "   MajorAxisLength  MinorAxisLength  Perimeter  ConvexArea  Centroid1  \\\n",
      "0             1.34             1.61      0.683       0.195       3.63   \n",
      "1             1.52             1.52      1.010       0.215       6.01   \n",
      "2             1.63             1.38      1.110       0.182       6.55   \n",
      "3             2.04             2.12      0.715       0.371      10.30   \n",
      "4             7.78             6.21      6.800       4.440      14.00   \n",
      "\n",
      "   Centroid2    Area  raddi  microorganisms  \n",
      "0      12.10   1.310   7.99       Spirogyra  \n",
      "1      20.60   0.765   7.99       Spirogyra  \n",
      "2      11.50   0.953   7.99       Spirogyra  \n",
      "3      12.00   2.340   7.99       Spirogyra  \n",
      "4       9.55  17.600   7.99       Spirogyra  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'D:/GEN AI/textPreprocessing/microbes.csv'\n",
    ")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb0bc33f-90e0-4e7a-aec7-02c807315673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank   NCT Number                                              Title  \\\n",
      "0     1  NCT04896970  Risk of SARS-CoV-2 Infection (COVID-19) in a S...   \n",
      "1     2  NCT04581148  SARS-CoV2 Antibodies in Pediatric Patients (CO...   \n",
      "2     3  NCT04605757  Long-term Evolution of Pulmonary Involvement o...   \n",
      "3     4  NCT04779944  Impact of SARS-CoV-2 Pandemic on Psychological...   \n",
      "4     5  NCT04414241  Hydroxychloroquine to Prevent SARS-CoV-2 Infec...   \n",
      "\n",
      "          Acronym      Status         Study Results            Conditions  \\\n",
      "0      ConcerTest   Withdrawn  No Results Available            SARS-CoV-2   \n",
      "1  SARS-CoV2_KIDS  Recruiting  No Results Available             SARS-Cov2   \n",
      "2             NaN  Recruiting  No Results Available  SARS-COV-2 Pneumonia   \n",
      "3             NaN   Completed  No Results Available            SARS-CoV-2   \n",
      "4             NaN   Completed  No Results Available            SARS-CoV-2   \n",
      "\n",
      "                                       Interventions  \\\n",
      "0                                     Other: Concert   \n",
      "1  Diagnostic Test: Blood test antibodies against...   \n",
      "2  Other: Clinical, functional and radiological l...   \n",
      "3                                       Other: other   \n",
      "4                           Drug: Hydroxychloroquine   \n",
      "\n",
      "                                    Outcome Measures  \\\n",
      "0  SARS-CoV-2 incidence|Time to screen all partic...   \n",
      "1  Prevalence of antibodies against SARS-CoV-2 at...   \n",
      "2  Long term evolution of clinical involvement du...   \n",
      "3  Questionnaire to assess the psychological impa...   \n",
      "4  Efficacy: Proportion of participants with posi...   \n",
      "\n",
      "                               Sponsor/Collaborators  ...           Other IDs  \\\n",
      "0                   University Hospital, Montpellier  ...      RECHMPL21_0110   \n",
      "1     University of Erlangen-Nürnberg Medical School  ...           405_20 Bc   \n",
      "2  IRCCS Azienda Ospedaliero-Universitaria di Bol...  ...  714/2020/Oss/AOUBo   \n",
      "3                                  Assiut University  ...         AssiutU1235   \n",
      "4               Universidad Peruana Cayetano Heredia  ...        202087|20923   \n",
      "\n",
      "        Start Date Primary Completion Date    Completion Date  \\\n",
      "0        June 2021               July 2021          July 2021   \n",
      "1  October 1, 2020           June 30, 2022      June 30, 2022   \n",
      "2    July 30, 2020          April 30, 2021      July 30, 2021   \n",
      "3    April 7, 2020           July 30, 2020    August 15, 2020   \n",
      "4    June 25, 2020       November 23, 2020  November 23, 2020   \n",
      "\n",
      "       First Posted Results First Posted Last Update Posted  \\\n",
      "0      May 21, 2021                  NaN   October 20, 2021   \n",
      "1   October 9, 2020                  NaN   January 27, 2022   \n",
      "2  October 28, 2020                  NaN   January 12, 2021   \n",
      "3     March 3, 2021                  NaN      March 3, 2021   \n",
      "4      June 4, 2020                  NaN   October 28, 2021   \n",
      "\n",
      "                                           Locations Study Documents  \\\n",
      "0                                                NaN             NaN   \n",
      "1    University Hospital Erlangen, Erlangen, Germany             NaN   \n",
      "2  Respiratory and Critical Care Unit - S.Orsola-...             NaN   \n",
      "3                          heba Yassa, Assiut, Egypt             NaN   \n",
      "4  Centro Médico Naval \"Cirujano Mayor Santiago T...             NaN   \n",
      "\n",
      "                                           URL  \n",
      "0  https://ClinicalTrials.gov/show/NCT04896970  \n",
      "1  https://ClinicalTrials.gov/show/NCT04581148  \n",
      "2  https://ClinicalTrials.gov/show/NCT04605757  \n",
      "3  https://ClinicalTrials.gov/show/NCT04779944  \n",
      "4  https://ClinicalTrials.gov/show/NCT04414241  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\n",
    "    'D:/GEN AI/textPreprocessing/covid_clinical_trials.csv'\n",
    ")\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549e48bb-880c-47fa-b9ea-e25e5cdb599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 symbol                                 name     price  \\\n",
      "0           0   AAPL              Apple Inc. Common Stock   157.510   \n",
      "1           1   MSFT   Microsoft Corporation Common Stock   289.560   \n",
      "2           2   GOOG  Alphabet Inc. Class C Capital Stock  2639.755   \n",
      "3           3  GOOGL   Alphabet Inc. Class A Common Stock  2629.010   \n",
      "4           4   AMZN        Amazon.com, Inc. Common Stock  3009.070   \n",
      "\n",
      "  pricing_changes pricing_percentage_changes             sector  \\\n",
      "0           +2.42                   (+1.56%)         Technology   \n",
      "1           +2.41                   (+0.84%)         Technology   \n",
      "2         +46.545                   (+1.79%)         Technology   \n",
      "3          +45.05                   (+1.74%)         Technology   \n",
      "4          +61.74                   (+2.09%)  Consumer Services   \n",
      "\n",
      "                                  industry         market_cap share_volume  \\\n",
      "0                   Computer Manufacturing  2,699,423,838,000   63,429,579   \n",
      "1  Computer Software: Prepackaged Software  2,143,429,080,429   22,790,662   \n",
      "2        Internet and Information Services  1,724,718,735,878      900,760   \n",
      "3        Internet and Information Services  1,718,961,675,672    1,008,687   \n",
      "4           Catalog/Specialty Distribution  1,511,267,897,700    2,623,915   \n",
      "\n",
      "  earnings_per_share annualized_dividend dividend_pay_date symbol_yield  beta  \\\n",
      "0              $6.04               $0.88      Feb 10, 2022        0.58%  1.18   \n",
      "1              $9.39               $2.48       Jun 9, 2022         0.9%  0.91   \n",
      "2            $112.23                 NaN               NaN          NaN  1.06   \n",
      "3            $112.23                 NaN               NaN          NaN  1.06   \n",
      "4             $64.78                 NaN               NaN          NaN  1.11   \n",
      "\n",
      "   errors  \n",
      "0   False  \n",
      "1   False  \n",
      "2   False  \n",
      "3   False  \n",
      "4   False  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'D:/GEN AI/textPreprocessing/2022_03_17_02_06_nasdaq.csv'\n",
    ")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6bc9774-0ee9-4c8e-acdb-36b2330fda72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  Age Childish diseases Accident or serious trauma  \\\n",
      "0  spring   30                no                        yes   \n",
      "1  spring   35               yes                         no   \n",
      "2  spring   27               yes                         no   \n",
      "3  spring   32                no                        yes   \n",
      "4  spring   30               yes                        yes   \n",
      "\n",
      "  Surgical intervention High fevers in the last year  \\\n",
      "0                   yes       more than 3 months ago   \n",
      "1                   yes       more than 3 months ago   \n",
      "2                    no       more than 3 months ago   \n",
      "3                   yes       more than 3 months ago   \n",
      "4                    no       more than 3 months ago   \n",
      "\n",
      "  Frequency of alcohol consumption Smoking habit  \\\n",
      "0                      once a week    occasional   \n",
      "1                      once a week         daily   \n",
      "2             hardly ever or never         never   \n",
      "3             hardly ever or never         never   \n",
      "4                      once a week         never   \n",
      "\n",
      "   Number of hours spent sitting per day Diagnosis  \n",
      "0                                     16    Normal  \n",
      "1                                      6   Altered  \n",
      "2                                      9    Normal  \n",
      "3                                      7    Normal  \n",
      "4                                      9   Altered  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'D:/GEN AI/textPreprocessing/fertility.csv'\n",
    ")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7712b72d-de5e-4675-bde3-94174f92c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Image Index                                     Finding Labels  \\\n",
      "0  00000013_005.png  Emphysema|Infiltration|Pleural_Thickening|Pneu...   \n",
      "1  00000013_026.png                             Cardiomegaly|Emphysema   \n",
      "2  00000017_001.png                                         No Finding   \n",
      "3  00000030_001.png                                        Atelectasis   \n",
      "4  00000032_001.png                        Cardiomegaly|Edema|Effusion   \n",
      "\n",
      "   Follow-up #  Patient ID Patient Age Patient Gender View Position  \\\n",
      "0            5          13        060Y              M            AP   \n",
      "1           26          13        057Y              M            AP   \n",
      "2            1          17        077Y              M            AP   \n",
      "3            1          30        079Y              M            PA   \n",
      "4            1          32        055Y              F            AP   \n",
      "\n",
      "   OriginalImageWidth  OriginalImageHeight  OriginalImagePixelSpacing_x  \\\n",
      "0                3056                 2544                        0.139   \n",
      "1                2500                 2048                        0.168   \n",
      "2                2500                 2048                        0.168   \n",
      "3                2992                 2991                        0.143   \n",
      "4                2500                 2048                        0.168   \n",
      "\n",
      "   OriginalImagePixelSpacing_y  \n",
      "0                        0.139  \n",
      "1                        0.168  \n",
      "2                        0.168  \n",
      "3                        0.143  \n",
      "4                        0.168  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'D:/GEN AI/textPreprocessing/sample_labels.csv'\n",
    ")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8612abe-33aa-4318-b794-482ad9e1d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\ayesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "446538f1-1ebb-45ab-b994-168784d520d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4251c8bc-c1ce-45dc-afa2-a364baa4369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Get a list of all file ids (i.e., text names) in the Gutenberg Corpus\n",
    "file_ids = gutenberg.fileids()\n",
    "print(file_ids)\n",
    "\n",
    "# Access a specific text from the Gutenberg Corpus\n",
    "emma_text = gutenberg.raw('austen-emma.txt')\n",
    "text = emma_text[:1000]  # Print the first 500 characters of the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b57a8e2-8dc0-4370-9adc-bd49723f6a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.\\n\\nShe was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.  Her mother\\nhad died too long ago for her to have more than an indistinct\\nremembrance of her caresses; and her place had been supplied\\nby an excellent woman as governess, who had fallen little short\\nof a mother in affection.\\n\\nSixteen years had Miss Taylor been in Mr. Woodhouse's family,\\nless as a governess than a friend, very fond of both daughters,\\nbut particularly of Emma.  Between _them_ it was more the intimacy\\nof sisters.  Even before Miss Taylor had ceased to hold the nominal\\noffice of governess, the mildness o\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9130f2e9-f784-4b20-900a-231be0cd93a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her. She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period. Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection. Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma. Between _them_ it was more the intimacy of sisters. Even before Miss Taylor had ceased to hold the nominal office of governess, the mildness o\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_wide_spaces_to_single(text):\n",
    "    # Replace multiple whitespace characters (spaces, tabs, newlines) with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Sample text\n",
    "sample_text = text\n",
    "\n",
    "# Clean the text\n",
    "cleaned_text = convert_wide_spaces_to_single(sample_text)\n",
    "\n",
    "# Print the cleaned text\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ca20609-9a6b-44c0-b15b-f606d0123af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bf00df1-19e3-4e22-bb9b-14e7dd425198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emma by Jane Austen 1816 VOLUME I CHAPTER I Emma Woodhouse handsome clever and rich with a comfortable home and happy disposition seemed to unite some of the best blessings of existence and had lived nearly twentyone years in the world with very little to distress or vex her She was the youngest of the two daughters of a most affectionate indulgent father and had in consequence of her sisters marriage been mistress of his house from a very early period Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses and her place had been supplied by an excellent woman as governess who had fallen little short of a mother in affection Sixteen years had Miss Taylor been in Mr Woodhouses family less as a governess than a friend very fond of both daughters but particularly of Emma Between them it was more the intimacy of sisters Even before Miss Taylor had ceased to hold the nominal office of governess the mildness o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuations_and_special_chars(text):\n",
    "    # Define the pattern to match any character that is not a word character, space, or newline\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    # Use re.sub() to replace the matched characters with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her. She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period. Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection. Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma. Between _them_ it was more the intimacy of sisters. Even before Miss Taylor had ceased to hold the nominal office of governess, the mildness o\n",
    "\"\"\"\n",
    "\n",
    "# Clean the text\n",
    "cleaned_text = remove_punctuations_and_special_chars(sample_text)\n",
    "\n",
    "# Print the cleaned text\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d8dffa2-f0c1-4a6b-a0d4-fab0a6de0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ade94ba2-2efd-4bdc-b50e-7d1cbb1d89fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ayesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure the necessary datasets are downloaded\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72329aef-6d32-46f1-964a-f8871e0583b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Jane Austen 1816 VOLUME CHAPTER Emma Woodhouse handsome clever rich comfortable home happy disposition seemed unite best blessings existence lived nearly twentyone years world little distress vex youngest two daughters affectionate indulgent father consequence sisters marriage mistress house early period mother died long ago indistinct remembrance caresses place supplied excellent woman governess fallen little short mother affection Sixteen years Miss Taylor Mr Woodhouses family less governess friend fond daughters particularly Emma intimacy sisters Even Miss Taylor ceased hold nominal office governess mildness\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuations_and_special_chars(text):\n",
    "    # Define the pattern to match any character that is not a word character, space, or newline\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    # Use re.sub() to replace the matched characters with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    # Filter out the stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    # Join the filtered words back into a single string\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    return cleaned_text\n",
    "    # Sample text\n",
    "sample_text = text\n",
    "\n",
    "# Clean the text by removing punctuations and special characters\n",
    "cleaned_text = remove_punctuations_and_special_chars(sample_text)\n",
    "\n",
    "# Further clean the text by removing stopwords\n",
    "cleaned_text = remove_stopwords(cleaned_text)\n",
    "\n",
    "# Print the cleaned text\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67b73804-624a-44fc-ba29-1c5eeba7a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3747380-79c7-4d40-91aa-5dd0d64adf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ayesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ayesh\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure the necessary datasets are downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e2f90f6-cef8-438d-b65e-6ef7eb0080c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Jane Austen 1816 VOLUME CHAPTER Emma Woodhouse handsome clever rich comfortable home happy disposition seemed unite best blessing existence lived nearly twentyone year world little distress vex youngest two daughter affectionate indulgent father consequence sister marriage mistress house early period mother died long ago indistinct remembrance caress place supplied excellent woman governess fallen little short mother affection Sixteen year Miss Taylor Mr Woodhouses family le governess friend fond daughter particularly Emma intimacy sister Even Miss Taylor ceased hold nominal office governess mildness\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuations_and_special_chars(text):\n",
    "    # Define the pattern to match any character that is not a word character, space, or newline\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    # Use re.sub() to replace the matched characters with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    # Filter out the stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    # Join the filtered words back into a single string\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    return cleaned_text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    # Lemmatize each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Join the lemmatized words back into a single string\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her. She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period. Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection. Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma. Between _them_ it was more the intimacy of sisters. Even before Miss Taylor had ceased to hold the nominal office of governess, the mildness o\n",
    "\"\"\"\n",
    "\n",
    "# Clean the text by removing punctuations and special characters\n",
    "cleaned_text = remove_punctuations_and_special_chars(sample_text)\n",
    "\n",
    "# Further clean the text by removing stopwords\n",
    "cleaned_text = remove_stopwords(cleaned_text)\n",
    "\n",
    "# Apply lemmatization to the cleaned text\n",
    "lemmatized_text = lemmatize_text(cleaned_text)\n",
    "\n",
    "# Print the lemmatized text\n",
    "print(lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c46858a2-a1a7-46bb-9637-cdf03217ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1fece31-8bee-4b4a-a7de-ff1fe97ba84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ayesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure the necessary datasets are downloaded\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1d8a9b2-871a-420e-899e-d03751cf9b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'Jane', 'Austen', '1816', 'VOLUME', 'CHAPTER', 'Emma', 'Woodhouse', 'handsome', 'clever', 'rich', 'comfortable', 'home', 'happy', 'disposition', 'seemed', 'unite', 'best', 'blessing', 'existence', 'lived', 'nearly', 'twentyone', 'year', 'world', 'little', 'distress', 'vex', 'youngest', 'two', 'daughter', 'affectionate', 'indulgent', 'father', 'consequence', 'sister', 'marriage', 'mistress', 'house', 'early', 'period', 'mother', 'died', 'long', 'ago', 'indistinct', 'remembrance', 'caress', 'place', 'supplied', 'excellent', 'woman', 'governess', 'fallen', 'little', 'short', 'mother', 'affection', 'Sixteen', 'year', 'Miss', 'Taylor', 'Mr', 'Woodhouses', 'family', 'le', 'governess', 'friend', 'fond', 'daughter', 'particularly', 'Emma', 'intimacy', 'sister', 'Even', 'Miss', 'Taylor', 'ceased', 'hold', 'nominal', 'office', 'governess', 'mildness']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuations_and_special_chars(text):\n",
    "    # Define the pattern to match any character that is not a word character, space, or newline\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    # Use re.sub() to replace the matched characters with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Split the text into words\n",
    "    words = word_tokenize(text)\n",
    "    # Filter out the stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    # Join the filtered words back into a single string\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    return cleaned_text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Split the text into words\n",
    "    words = word_tokenize(text)\n",
    "    # Lemmatize each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Join the lemmatized words back into a single string\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "# Sample text\n",
    "sample_text = text\n",
    "\n",
    "# Clean the text by removing punctuations and special characters\n",
    "cleaned_text = remove_punctuations_and_special_chars(sample_text)\n",
    "\n",
    "# Further clean the text by removing stopwords\n",
    "cleaned_text = remove_stopwords(cleaned_text)\n",
    "\n",
    "# Apply lemmatization to the cleaned text\n",
    "lemmatized_text = lemmatize_text(cleaned_text)\n",
    "\n",
    "# Tokenize the lemmatized text\n",
    "tokens = word_tokenize(lemmatized_text)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51db43-daac-4441-ab01-b254c6a0a507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
